{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cIb2nr3Q6Ta",
        "outputId": "067163b4-392c-47f8-807c-cf6175c2bb59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OwSA9u3eROQ5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Change to your working directory in Google Drive\n",
        "project_path = '/content/drive/MyDrive/Amazon/'\n",
        "os.chdir(project_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "U64gunYJR31N",
        "outputId": "bd9bcbcc-4d9c-49a7-e5a0-a15bdcaacea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-81d10806847b>\u001b[0m in \u001b[0;36mdownload_images_from_links\u001b[0;34m(df, image_column, download_folder, num_threads)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Submit download tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_links\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-81d10806847b>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Submit download tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_links\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WorkItem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;34m\"\"\"Initializes the future. Should not be called by clients.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lock)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_waiters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-81d10806847b>\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Download all images from train.csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mdownload_images_from_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All image downloads complete.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-81d10806847b>\u001b[0m in \u001b[0;36mdownload_images_from_links\u001b[0;34m(df, image_column, download_folder, num_threads)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Use ThreadPoolExecutor to download images in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_threads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Submit download tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_links\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip install tqdm requests  # Install required libraries if not already done\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm  # For progress bar\n",
        "\n",
        "# Define folder to store downloaded images\n",
        "download_folder = '/content/drive/MyDrive/Amazon/resource/dataset/images/'\n",
        "\n",
        "# Ensure the folder exists\n",
        "if not os.path.exists(download_folder):\n",
        "    os.makedirs(download_folder)\n",
        "\n",
        "# Load the full train.csv file from Google Drive\n",
        "input_csv = '/content/drive/MyDrive/Amazon/resource/dataset/train.csv'  # Replace with your actual file path\n",
        "df = pd.read_csv(input_csv)\n",
        "\n",
        "\n",
        "# Define the column that contains image links\n",
        "image_column = 'image_link'  # Ensure this matches the name of the column in your CSV\n",
        "\n",
        "# Function to download a single image\n",
        "def download_image(image_link, download_folder):\n",
        "    try:\n",
        "        # Extract image name from the link\n",
        "        image_name = Path(image_link).name\n",
        "        image_path = os.path.join(download_folder, image_name)\n",
        "\n",
        "        # Download the image\n",
        "        response = requests.get(image_link, stream=True)\n",
        "        response.raise_for_status()  # Check if the request was successful\n",
        "\n",
        "        # Save the image in chunks to avoid memory issues\n",
        "        with open(image_path, 'wb') as file:\n",
        "            for chunk in response.iter_content(chunk_size=8192):  # 8KB chunks\n",
        "                file.write(chunk)\n",
        "\n",
        "        return image_link, True\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading {image_link}: {e}\")\n",
        "        return image_link, False\n",
        "\n",
        "# Function to download images in parallel with a progress bar\n",
        "def download_images_from_links(df, image_column, download_folder, num_threads=8):\n",
        "    # Get unique image links\n",
        "    image_links = df[image_column].dropna().unique()\n",
        "\n",
        "    # Use ThreadPoolExecutor to download images in parallel\n",
        "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "        # Submit download tasks\n",
        "        futures = {executor.submit(download_image, link, download_folder): link for link in image_links}\n",
        "\n",
        "        # Monitor progress with tqdm\n",
        "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Downloading images\"):\n",
        "            link = futures[future]\n",
        "            try:\n",
        "                link, success = future.result()\n",
        "                if success:\n",
        "                    pass  # Image downloaded successfully\n",
        "                else:\n",
        "                    print(f\"Failed to download {link}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Exception occurred for {link}: {e}\")\n",
        "\n",
        "# Download all images from train.csv\n",
        "download_images_from_links(df, image_column, download_folder)\n",
        "\n",
        "print(\"All image downloads complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "s1oOHH7HJy3P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your original CSV file from Google Drive\n",
        "csv_file_path = '/content/drive/MyDrive/Amazon/resource/dataset/train.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Extract the first 20000 rows\n",
        "sample_df = df.head(20000)\n",
        "# Save these rows as a new CSV file (sample_train.csv) in Google Drive\n",
        "sample_csv_path = '/content/drive/MyDrive/Amazon/resource/dataset/sample_trainImage.csv'\n",
        "sample_df.to_csv(sample_csv_path, index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpdY0PSakPMP",
        "outputId": "a5ad8ff5-ace8-453f-bf81-528c799092ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-02a5281a5b2a>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  step_df['index_2'] = step_df.index\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your original CSV file from Google Drive\n",
        "csv_file_path = '/content/drive/MyDrive/Amazon/resource/dataset/train.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Extract the first 20000 rows\n",
        "sample_df = df.head(20000)\n",
        "\n",
        "sample_df = sample_df.reset_index(drop=True)\n",
        "# Assuming 'image_url' column contains the image URLs\n",
        "sample_df['image_name'] = sample_df['image_link'].str.split('/').str[-1].str.replace('.jpg', '')\n",
        "step_df = sample_df[['image_link','entity_name','entity_value','group_id','image_name']]\n",
        "step_df['index_2'] = step_df.index\n",
        "sample_csv_path = '/content/drive/MyDrive/Amazon/resource/dataset/sample_trainImage.csv'\n",
        "step_df.to_csv(sample_csv_path, index=True, index_label='index') # Set index=True to include the image names as index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "Y07h51JoQgDx",
        "outputId": "2ab39ed4-7e96-429f-934c-0ddbf136b2d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.10/dist-packages (1.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.0+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.23.2)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.6.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.6)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.3.0.post5)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2024.6.1)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.8.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path, map_location=device)\n",
            "Extracting text:  10%|â–ˆ         | 2/20 [01:51<16:42, 55.68s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-da430579f925>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Extract text from the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mextracted_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Store the extracted text in the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'extracted_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextracted_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-da430579f925>\u001b[0m in \u001b[0;36mextract_text_from_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Read text from the image using EasyOCR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mocr_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Join all detected text into a single string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/easyocr.py\u001b[0m in \u001b[0;36mreadtext\u001b[0;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cv_grey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreformat_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         horizontal_list, free_list = self.detect(img, \n\u001b[0m\u001b[1;32m    457\u001b[0m                                                  \u001b[0mmin_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                                                  \u001b[0mlow_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlow_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlink_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/easyocr.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, img, min_size, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, add_margin, reformat, optimal_num_chars, threshold, bbox_min_score, bbox_min_size, max_candidates)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cv_grey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreformat_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         text_box_list = self.get_textbox(self.detector, \n\u001b[0m\u001b[1;32m    322\u001b[0m                                     \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                                     \u001b[0mcanvas_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcanvas_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/detection.py\u001b[0m in \u001b[0;36mget_textbox\u001b[0;34m(detector, image, canvas_size, mag_ratio, text_threshold, link_threshold, low_text, poly, device, optimal_num_chars, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mestimate_num_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimal_num_chars\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     bboxes_list, polys_list = test_net(canvas_size, mag_ratio, detector,\n\u001b[0m\u001b[1;32m     96\u001b[0m                                        \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                                        \u001b[0mlink_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/detection.py\u001b[0m in \u001b[0;36mtest_net\u001b[0;34m(canvas_size, mag_ratio, net, image, text_threshold, link_threshold, low_text, poly, device, estimate_num_chars)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mboxes_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolys_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/craft.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;34m\"\"\" Base network \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0msources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;34m\"\"\" U network \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/model/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mh_relu2_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 454\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    455\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip install easyocr\n",
        "import os\n",
        "import pandas as pd\n",
        "import easyocr\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Initialize EasyOCR with GPU support\n",
        "ocr_reader = easyocr.Reader(['en'], gpu=True)  # Set gpu=False if not using GPU\n",
        "# df = pd.read_csv('/content/drive/MyDrive/Amazon/resource/dataset/train.csv')\n",
        "# sample_df = df.head(20000)\n",
        "# sample_df.to_csv('/content/drive/MyDrive/Amazon/resource/dataset/sample_train.csv', index=False)\n",
        "# Load the CSV file with image paths\n",
        "input_csv = '/content/drive/MyDrive/Amazon/resource/dataset/sample_trainImage.csv'\n",
        "df = pd.read_csv(input_csv)\n",
        "\n",
        "# Process only the first 20000 rows\n",
        "df = df.head(20000)\n",
        "\n",
        "# Folder where the images are stored\n",
        "image_folder = '/content/drive/MyDrive/Amazon/resource/dataset/images/'\n",
        "\n",
        "# Function to extract text from an image\n",
        "def extract_text_from_image(image_path):\n",
        "    try:\n",
        "        # Read text from the image using EasyOCR\n",
        "        results = ocr_reader.readtext(image_path)\n",
        "        # Join all detected text into a single string\n",
        "        text = \" \".join([result[1] for result in results])\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {image_path}: {e}\")\n",
        "        return \"Error\"\n",
        "\n",
        "# Add a new column for extracted text in the dataframe\n",
        "df['extracted_text'] = \"\"\n",
        "\n",
        "# Iterate through each image path and extract text with a progress bar\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Extracting text\"):\n",
        "    # Use 'image_link' instead of 'image_path'\n",
        "    x=row['image_link']\n",
        "    prefix_to_remove = \"https://m.media-amazon.com/images/I/\"\n",
        "    trimmed_x = x.replace(prefix_to_remove, \"\")\n",
        "    image_path = os.path.join(image_folder, row['image_name']+'.jpg')\n",
        "\n",
        "    if os.path.exists(image_path):\n",
        "        # Extract text from the image\n",
        "        extracted_text = extract_text_from_image(image_path)\n",
        "        # Store the extracted text in the dataframe\n",
        "        df.at[idx, 'extracted_text'] = extracted_text\n",
        "    else:\n",
        "        print(extracted_text)\n",
        "        df.at[idx, 'extracted_text'] = \"Image not found\"\n",
        "\n",
        "# Save the updated dataframe with extracted text to a new CSV file\n",
        "output_csv = '/content/drive/MyDrive/Amazon/resource/dataset/sample_trainExtracted.csv'\n",
        "df.to_csv(output_csv, index=False)\n",
        "print(f\"Text extraction complete. Updated CSV saved to {output_csv}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnIfkXrgVbR_",
        "outputId": "3a35861e-5372-415b-8034-62b7a06bbb6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cleaning text: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 3398.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data cleaning complete. Updated CSV saved to /content/drive/MyDrive/Amazon/resource/dataset/sample_trainCleaned.csv.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transforming Text: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 4100.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF features extracted and saved to '/content/drive/MyDrive/Amazon/resource/dataset/sample_trainTfidf.csv'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the CSV file with the extracted text\n",
        "input_csv = '/content/drive/MyDrive/Amazon/resource/dataset/sample_trainExtracted.csv'\n",
        "df = pd.read_csv(input_csv)\n",
        "\n",
        "# Function to clean and preprocess text\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text)     # Replace multiple spaces with a single space\n",
        "    text = text.strip()                  # Remove leading and trailing spaces\n",
        "    return text\n",
        "\n",
        "tqdm.pandas(desc=\"Cleaning text\")\n",
        "df['cleaned_text'] = df['extracted_text'].progress_apply(preprocess_text)\n",
        "\n",
        "# Save the cleaned data to a new CSV file\n",
        "output_csv = '/content/drive/MyDrive/Amazon/resource/dataset/sample_trainCleaned.csv'\n",
        "df.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"Data cleaning complete. Updated CSV saved to {output_csv}.\")\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the combined CSV file\n",
        "df_combined = pd.read_csv('/content/drive/MyDrive/Amazon/resource/dataset/sample_trainCleaned.csv')\n",
        "\n",
        "df_combined['cleaned_text'] = df_combined['cleaned_text'].fillna('')\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Fit and transform the cleaned text data with progress bar\n",
        "tqdm.pandas(desc=\"Fitting TF-IDF Vectorizer\")\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(tqdm(df_combined['cleaned_text'], desc=\"Transforming Text\"))\n",
        "\n",
        "# Convert the TF-IDF matrix to a DataFrame\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "# Concatenate the original DataFrame with the TF-IDF features\n",
        "df_final = pd.concat([df_combined, tfidf_df], axis=1)\n",
        "\n",
        "# Drop the original 'cleaned_text' column\n",
        "df_final = df_final.drop(columns=['cleaned_text'])\n",
        "\n",
        "# Save the final DataFrame with TF-IDF features to a new CSV file\n",
        "output_csv = '/content/drive/MyDrive/Amazon/resource/dataset/sample_trainTfidf.csv'\n",
        "df_final.to_csv(output_csv, index=False)\n",
        "print(\"TF-IDF features extracted and saved to '/content/drive/MyDrive/Amazon/resource/dataset/sample_trainTfidf.csv'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f82i5czEV1wE",
        "outputId": "c2460fcd-0315-4cc0-b788-dd2ea1aff312"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Preprocessing text: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 4734.78it/s]\n",
            "Extracting vectors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 2591.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2Vec features extracted and saved to '/content/drive/MyDrive/Amazon/resource/dataset/sample_trainWord2vec.csv'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the combined CSV file\n",
        "df_combined = pd.read_csv('/content/drive/MyDrive/Amazon/resource/dataset/sample_trainCleaned.csv')\n",
        "\n",
        "df_combined['cleaned_text'] = df_combined['cleaned_text'].fillna('')\n",
        "# Prepare text data for Word2Vec\n",
        "def preprocess_text(text):\n",
        "    return simple_preprocess(text)\n",
        "\n",
        "# Preprocess the cleaned text data with a progress bar\n",
        "tqdm.pandas(desc=\"Preprocessing text\")\n",
        "texts = df_combined['cleaned_text'].progress_apply(preprocess_text)\n",
        "\n",
        "# Train a Word2Vec model (or load a pre-trained model)\n",
        "word2vec_model = Word2Vec(sentences=texts, vector_size=100, window=5, min_count=1, sg=0)\n",
        "\n",
        "def get_avg_word_vector(text):\n",
        "    vectors = [word2vec_model.wv[word] for word in text if word in word2vec_model.wv]\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(word2vec_model.vector_size)\n",
        "\n",
        "# Apply the function to get the average word vectors with a progress bar\n",
        "tqdm.pandas(desc=\"Generating Word2Vec features\")\n",
        "word_vectors = np.array([get_avg_word_vector(text) for text in tqdm(texts.tolist(), desc=\"Extracting vectors\")])\n",
        "\n",
        "# Convert word vectors to a DataFrame\n",
        "word_vectors_df = pd.DataFrame(word_vectors, columns=[f'word2vec_{i}' for i in range(word_vectors.shape[1])])\n",
        "\n",
        "# Concatenate the original DataFrame with the Word2Vec features\n",
        "df_final = pd.concat([df_combined, word_vectors_df], axis=1)\n",
        "\n",
        "# Drop the original 'cleaned_text' column\n",
        "df_final = df_final.drop(columns=['cleaned_text'])\n",
        "\n",
        "# Save the final DataFrame with Word2Vec features to a new CSV file\n",
        "output_csv = '/content/drive/MyDrive/Amazon/resource/dataset/sample_trainWord2vec.csv'\n",
        "df_final.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"Word2Vec features extracted and saved to '{output_csv}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XLBB0HbXskX",
        "outputId": "eac8fc71-63f0-4c3e-f9a8-b57c8139e119"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:   0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:   5%|â–Œ         | 1/20 [00:02<00:51,  2.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  10%|â–ˆ         | 2/20 [00:03<00:24,  1.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  15%|â–ˆâ–Œ        | 3/20 [00:03<00:14,  1.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  20%|â–ˆâ–ˆ        | 4/20 [00:03<00:10,  1.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:04<00:08,  1.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:04<00:06,  2.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:04<00:05,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:05<00:04,  2.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:05<00:04,  2.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:05<00:03,  2.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:06<00:03,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:06<00:02,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:06<00:02,  2.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:07<00:02,  2.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:07<00:01,  3.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:07<00:01,  3.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:07<00:00,  3.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:08<00:00,  3.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting ResNet50 Features:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:08<00:00,  3.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting ResNet50 Features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:08<00:00,  2.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet50 features extracted and saved to '/content/drive/MyDrive/Amazon/resource/dataset/sample_trainResnet.csv'.\n",
            "Columns in df_tfidf: Index(['index', 'image_link', 'entity_name', 'entity_value', 'group_id',\n",
            "       'image_name', 'index_2', 'extracted_text', '00', '001',\n",
            "       ...\n",
            "       'xe', 'xi', 'xs', 'ye', 'you', 'youlike', 'your', 'yrda', 'yu', 'zu'],\n",
            "      dtype='object', length=1118)\n",
            "Columns in df_word2vec: Index(['index', 'image_link', 'entity_name', 'entity_value', 'group_id',\n",
            "       'image_name', 'index_2', 'extracted_text', 'word2vec_0', 'word2vec_1',\n",
            "       ...\n",
            "       'word2vec_90', 'word2vec_91', 'word2vec_92', 'word2vec_93',\n",
            "       'word2vec_94', 'word2vec_95', 'word2vec_96', 'word2vec_97',\n",
            "       'word2vec_98', 'word2vec_99'],\n",
            "      dtype='object', length=108)\n",
            "Columns in df_resnet: Index(['index', 'image_link', 'entity_name', 'entity_value', 'group_id',\n",
            "       'image_name', 'index_2', 'extracted_text', 'cleaned_text', 'resnet_0',\n",
            "       ...\n",
            "       'resnet_2038', 'resnet_2039', 'resnet_2040', 'resnet_2041',\n",
            "       'resnet_2042', 'resnet_2043', 'resnet_2044', 'resnet_2045',\n",
            "       'resnet_2046', 'resnet_2047'],\n",
            "      dtype='object', length=2057)\n",
            "Columns in df_cleaned: Index(['index', 'image_link', 'entity_name', 'entity_value', 'group_id',\n",
            "       'image_name', 'index_2', 'extracted_text', 'cleaned_text'],\n",
            "      dtype='object')\n",
            "All features combined and saved to 'sample_trainCombined.csv'.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load ResNet50 model pre-trained on ImageNet\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "# Function to preprocess and extract features from an image\n",
        "def extract_resnet_features(image_path):\n",
        "    try:\n",
        "        img = image.load_img(image_path, target_size=(224, 224))\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array = preprocess_input(img_array)\n",
        "        features = resnet_model.predict(img_array)\n",
        "        return features.flatten()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {image_path}: {e}\")\n",
        "        return np.zeros(resnet_model.output_shape[1])\n",
        "\n",
        "# Load the image paths from CSV\n",
        "df = pd.read_csv('/content/drive/MyDrive/Amazon/resource/dataset/sample_trainCleaned.csv')\n",
        "image_folder = '/content/drive/MyDrive/Amazon/resource/dataset/images/'\n",
        "\n",
        "# Extract features for each image with a progress bar\n",
        "features_list = []\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Extracting ResNet50 Features\"):\n",
        "    x=row['image_link']\n",
        "    prefix_to_remove = \"https://m.media-amazon.com/images/I/\"\n",
        "    trimmed_x = x.replace(prefix_to_remove, \"\")\n",
        "    image_path = os.path.join(image_folder, trimmed_x)\n",
        "    # image_path = os.path.join(image_folder, row['image_path'])\n",
        "    features = extract_resnet_features(image_path)\n",
        "    features_list.append(features)\n",
        "\n",
        "# Convert features to DataFrame\n",
        "resnet_features_df = pd.DataFrame(features_list, columns=[f'resnet_{i}' for i in range(features_list[0].shape[0])])\n",
        "\n",
        "# Combine with the original DataFrame\n",
        "df_final = pd.concat([df, resnet_features_df], axis=1)\n",
        "\n",
        "# Save the DataFrame with ResNet50 features\n",
        "df_final.to_csv('/content/drive/MyDrive/Amazon/resource/dataset/sample_trainResnet.csv', index=False)\n",
        "\n",
        "print(\"ResNet50 features extracted and saved to '/content/drive/MyDrive/Amazon/resource/dataset/sample_trainResnet.csv'.\")\n",
        "\n",
        "# print(df_cleaned.columns)\n",
        "# print(df_tfidf.columns)\n",
        "# print(df_word2vec.columns)\n",
        "# print(df_resnet.columns)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load all feature files and the cleaned text file\n",
        "df_tfidf = pd.read_csv('/content/drive/MyDrive/Amazon/resource/dataset/sample_trainTfidf.csv')\n",
        "df_word2vec = pd.read_csv('/content/drive/MyDrive/Amazon/resource/dataset/sample_trainWord2vec.csv')\n",
        "df_resnet = pd.read_csv('/content/drive/MyDrive/Amazon/resource/dataset/sample_trainResnet.csv')\n",
        "df_cleaned = pd.read_csv('/content/drive/MyDrive/Amazon/resource/dataset/sample_trainCleaned.csv')\n",
        "\n",
        "# Inspect columns to identify overlaps\n",
        "print(\"Columns in df_tfidf:\", df_tfidf.columns)\n",
        "print(\"Columns in df_word2vec:\", df_word2vec.columns)\n",
        "print(\"Columns in df_resnet:\", df_resnet.columns)\n",
        "print(\"Columns in df_cleaned:\", df_cleaned.columns)\n",
        "\n",
        "# Rename columns in each DataFrame to avoid overlap\n",
        "def rename_columns(df, prefix):\n",
        "    return df.rename(columns=lambda x: f'{prefix}_{x}' if x not in ['image_link', 'group_id', 'entity_name', 'entity_value', 'image_path', 'extracted_text', 'cleaned_text'] else x)\n",
        "\n",
        "df_tfidf = rename_columns(df_tfidf, 'tfidf')\n",
        "df_word2vec = rename_columns(df_word2vec, 'word2vec')\n",
        "df_resnet = rename_columns(df_resnet, 'resnet')\n",
        "\n",
        "# Reset index and set image_path as index for merging\n",
        "df_cleaned.set_index('image_link', inplace=True)\n",
        "df_tfidf.set_index('image_link', inplace=True)\n",
        "df_word2vec.set_index('image_link', inplace=True)\n",
        "df_resnet.set_index('image_link', inplace=True)\n",
        "\n",
        "# Perform the join operation while managing overlap\n",
        "df_combined = df_cleaned.join(df_tfidf, how='inner', lsuffix='_cleaned').join(df_word2vec, how='inner', rsuffix='_word2vec').join(df_resnet, how='inner', rsuffix='_resnet')\n",
        "\n",
        "# Reset index to get 'image_path' back as a column\n",
        "df_combined.reset_index(inplace=True)\n",
        "\n",
        "# Save the combined DataFrame\n",
        "df_combined.to_csv('/content/drive/MyDrive/Amazon/resource/dataset/sample_trainCombined.csv', index=False)\n",
        "\n",
        "print(\"All features combined and saved to 'sample_trainCombined.csv'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bEM8QDdXucU",
        "outputId": "5dc18248-11e0-4329-9e59-ab2389c5e5ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial rows: 20\n",
            "After filtering rows: 19\n",
            "X_train shape: (15, 1)\n",
            "X_test shape: (4, 1)\n",
            "y_value_train shape: (15,)\n",
            "y_value_test shape: (4,)\n",
            "y_unit_train shape: (15,)\n",
            "y_unit_test shape: (4,)\n",
            "Training numeric value model...\n",
            "Mean Squared Error for numeric value prediction: 81221.4060483775\n",
            "Training unit prediction model...\n",
            "Test_X columns: Index(['index'], dtype='object')\n",
            "Training_X columns: Index(['index'], dtype='object')\n",
            "Predictions saved to 'test_output.csv'.\n"
          ]
        }
      ],
      "source": [
        "# temporary\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import joblib\n",
        "\n",
        "# Define allowed units\n",
        "allowed_units = {\n",
        "    'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard',\n",
        "    'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton',\n",
        "    'kilovolt', 'millivolt', 'volt',\n",
        "    'kilowatt', 'watt',\n",
        "    'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce',\n",
        "    'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'\n",
        "}\n",
        "\n",
        "# Load the combined features dataset\n",
        "df_combined = pd.read_csv('/content/drive/MyDrive/Amazon/resource/dataset/sample_trainCombined.csv', usecols=['index', 'entity_value_cleaned'])\n",
        "\n",
        "# Focus on the first 20000 rows\n",
        "df_combined = df_combined.head(20000)\n",
        "df_combined = df_combined.rename(columns={'entity_value_cleaned': 'entity_value'})\n",
        "\n",
        "# Function to extract numeric value and unit\n",
        "def extract_value_and_unit(entity_value):\n",
        "    match = re.match(r\"([0-9.]+)\\s*([a-zA-Z\\s]+)\", entity_value)\n",
        "    if match:\n",
        "        value = float(match.group(1))\n",
        "        unit = match.group(2).strip()\n",
        "        return value, unit\n",
        "    return None, ''\n",
        "\n",
        "# Apply the extraction function\n",
        "df_combined[['numeric_value', 'unit']] = df_combined['entity_value'].apply(extract_value_and_unit).apply(pd.Series)\n",
        "\n",
        "# Replace NaN with empty strings in 'unit'\n",
        "df_combined['unit'] = df_combined['unit'].fillna('')\n",
        "\n",
        "# Filter rows where the numeric value is not NaN and unit is in allowed units\n",
        "# Check the initial and final shape of df_combined\n",
        "print(f\"Initial rows: {df_combined.shape[0]}\")\n",
        "df_combined = df_combined[df_combined['numeric_value'].notna()]\n",
        "df_combined = df_combined[df_combined['unit'].isin(allowed_units)]\n",
        "print(f\"After filtering rows: {df_combined.shape[0]}\")\n",
        "\n",
        "\n",
        "# Drop the original 'entity_value' column\n",
        "df_combined = df_combined.drop(columns=['entity_value'])\n",
        "\n",
        "# Replace NaN values with empty strings in the feature columns\n",
        "X = df_combined.drop(columns=['numeric_value', 'unit'])\n",
        "X = X.fillna('')\n",
        "\n",
        "# Prepare features and target\n",
        "y_value = df_combined['numeric_value']\n",
        "y_unit = df_combined['unit']\n",
        "\n",
        "# Ensure all features are numeric\n",
        "X = X.apply(pd.to_numeric, errors='ignore')\n",
        "X = X.select_dtypes(include=['number'])\n",
        "\n",
        "# Encode the unit labels\n",
        "unit_encoder = LabelEncoder()\n",
        "y_unit_encoded = unit_encoder.fit_transform(y_unit.fillna(''))\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_value_train, y_value_test, y_unit_train, y_unit_test = train_test_split(\n",
        "    X, y_value, y_unit_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "# Print the shapes of training and testing sets\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_value_train shape: {y_value_train.shape}\")\n",
        "print(f\"y_value_test shape: {y_value_test.shape}\")\n",
        "print(f\"y_unit_train shape: {y_unit_train.shape}\")\n",
        "print(f\"y_unit_test shape: {y_unit_test.shape}\")\n",
        "# Train model for numeric value prediction\n",
        "tqdm.write(\"Training numeric value model...\")\n",
        "value_model = RandomForestRegressor(n_estimators=10, random_state=42)\n",
        "value_model.fit(X_train, y_value_train)\n",
        "\n",
        "# Predict and evaluate numeric values\n",
        "y_value_pred = value_model.predict(X_test)\n",
        "mse = mean_squared_error(y_value_test, y_value_pred)\n",
        "tqdm.write(f\"Mean Squared Error for numeric value prediction: {mse}\")\n",
        "\n",
        "# Train model for unit prediction\n",
        "tqdm.write(\"Training unit prediction model...\")\n",
        "unit_model = RandomForestRegressor(n_estimators=10, random_state=42)\n",
        "unit_model.fit(X_train, y_unit_train)\n",
        "\n",
        "# Save the test data to a CSV file\n",
        "test_data = X_test.copy()\n",
        "test_data['numeric_value'] = y_value_test\n",
        "test_data['unit'] = y_unit_test\n",
        "\n",
        "# Ensure index is preserved in test_data\n",
        "test_data = test_data.reset_index(drop=False)\n",
        "test_data.rename(columns={'index': 'index'}, inplace=True)\n",
        "\n",
        "test_data.to_csv('test.csv', index=False)\n",
        "\n",
        "# Load the test data\n",
        "test_data = pd.read_csv('test.csv')\n",
        "test_X = test_data.drop(columns=['numeric_value'])\n",
        "\n",
        "# Ensure the feature columns in the test data match those used in training\n",
        "test_X = test_X[X.columns]\n",
        "# Ensure test_X columns match X columns\n",
        "print(f\"Test_X columns: {test_X.columns}\")\n",
        "print(f\"Training_X columns: {X.columns}\")\n",
        "# Ensure test features are numeric\n",
        "test_X = test_X.apply(pd.to_numeric, errors='ignore')\n",
        "test_X = test_X.select_dtypes(include=['number'])\n",
        "\n",
        "# Predict on the test data\n",
        "test_value_predictions = value_model.predict(test_X)\n",
        "test_unit_predictions = unit_model.predict(test_X)\n",
        "\n",
        "# Convert unit predictions back to original labels\n",
        "test_unit_predictions = unit_encoder.inverse_transform(test_unit_predictions.astype(int))\n",
        "\n",
        "# Format value predictions based on their type\n",
        "def format_value(value):\n",
        "    if value % 1 == 0:  # Check if the value is an integer\n",
        "        return int(value)\n",
        "    else:  # Format to 2 decimal places if it's a floating-point number\n",
        "        return round(value, 2)\n",
        "\n",
        "test_value_predictions = [format_value(value) for value in test_value_predictions]\n",
        "\n",
        "# Format predictions to include only allowed units\n",
        "test_data['entity_value'] = [f\"{value} {unit}\" for value, unit in zip(test_value_predictions, test_unit_predictions)]\n",
        "\n",
        "# Handle empty predictions\n",
        "test_data['entity_value'] = test_data['entity_value'].replace('', '*')\n",
        "\n",
        "# Save predictions to a CSV file, including the index\n",
        "test_data[['index', 'entity_value']].to_csv('/content/drive/MyDrive/Amazon/resource/dataset/test_output.csv', index=False)\n",
        "df = pd.read_csv('/content/drive/MyDrive/Amazon/resource/dataset/test_output.csv')\n",
        "\n",
        "# Rename the column\n",
        "df = df.rename(columns={'entity_value': 'prediction'})\n",
        "\n",
        "# Save the updated CSV\n",
        "df.to_csv('/content/drive/MyDrive/Amazon/resource/dataset/test_output.csv', index=False)\n",
        "\n",
        "tqdm.write(\"Predictions saved to 'test_output.csv'.\")\n",
        "\n",
        "# # Save the models\n",
        "joblib.dump(value_model, '/content/drive/MyDrive/Amazon/resource/dataset/value_model.pkl')\n",
        "joblib.dump(unit_model, '/content/drive/MyDrive/Amazon/resource/dataset/unit_model.pkl')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
